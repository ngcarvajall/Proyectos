
# üß© Proyecto 9: Clustering y Regresi√≥n

## üìñ Descripci√≥n
Este proyecto se centra en el an√°lisis de datos hist√≥ricos de facturas y √≥rdenes de clientes para identificar patrones de comportamiento y predecir ventas mediante t√©cnicas de *clustering* y modelos de regresi√≥n.

### **Retos iniciales**
- Un n√∫mero limitado de clientes (795), distribuidos en todas las regiones, mercados y pa√≠ses.
- Datos desglosados a nivel de art√≠culo dentro de las facturas, lo que requer√≠a consolidarlos a nivel de cliente para una mejor interpretaci√≥n.
- Duplicidad en los identificadores de clientes (`Customer ID`), lo que llev√≥ a la necesidad de agrupar los datos por el nombre del cliente para realizar el an√°lisis.

### **Variable objetivo**
La variable objetivo elegida fue **`Sales`**, por lo que todos los modelos se centraron en la predicci√≥n de este valor.

---

## üóÇÔ∏è Estructura del Proyecto

```
üì¶ PROYECTO9_CLUSTERING_REGRESION
‚îú‚îÄ‚îÄ üìÇ Datos                
‚îÇ   ‚îú‚îÄ‚îÄ Datos_Modelo_1/     # Datos procesados para el modelo 1
‚îÇ   ‚îú‚îÄ‚îÄ Datos_Modelo_2/     # Datos procesados para el modelo 2
‚îÇ   ‚îú‚îÄ‚îÄ Datos_Modelo_3/     # Datos procesados para el modelo 3
‚îÇ   ‚îú‚îÄ‚îÄ df_cluster_0.csv    # Cluster 0 generado
‚îÇ   ‚îú‚îÄ‚îÄ df_cluster_1.csv    # Cluster 1 generado
‚îÇ   ‚îú‚îÄ‚îÄ df_predecir_0.csv   # Predicciones para el Cluster 0
‚îÇ   ‚îú‚îÄ‚îÄ df_predecir_1.csv   # Predicciones para el Cluster 1
‚îÇ   ‚îî‚îÄ‚îÄ Global_Superstore.csv # Datos originales sin procesar
‚îú‚îÄ‚îÄ üìÇ Notebooks            
‚îÇ   ‚îú‚îÄ‚îÄ Modelo_1.ipynb      # Notebooks con el an√°lisis y modelo 1
‚îÇ   ‚îú‚îÄ‚îÄ Modelo_2.ipynb      # Notebooks con el an√°lisis y modelo 2
‚îÇ   ‚îú‚îÄ‚îÄ Modelo_3.ipynb      # Notebooks con el an√°lisis y modelo 3
‚îÇ   ‚îî‚îÄ‚îÄ EDA.ipynb           # An√°lisis exploratorio de datos
‚îú‚îÄ‚îÄ üìÇ src                  # Scripts para procesamiento y modelado
‚îî‚îÄ‚îÄ README.md               # Descripci√≥n general del proyecto
```

---

## üõ†Ô∏è Instalaci√≥n y Requisitos

El proyecto fue desarrollado en Python 3.9. Para reproducir los an√°lisis, aseg√∫rate de instalar las siguientes dependencias:

- [`pandas`](https://pandas.pydata.org/)
- [`numpy`](https://numpy.org/)
- [`matplotlib`](https://matplotlib.org/)
- [`seaborn`](https://seaborn.pydata.org/)
- [`scikit-learn`](https://scikit-learn.org/stable/)
- [`scipy`](https://scipy.org/)

Instala las dependencias con el siguiente comando:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn scipy
```

---

## üöÄ Metodolog√≠a

### **Preparaci√≥n de Datos y Clustering**
Se gener√≥ un nuevo DataFrame consolidado a nivel de cliente con las siguientes m√©tricas clave:
- **`facturas_total`**: N√∫mero total de √≥rdenes por cliente.
- **`descuento_medio`**: Promedio de descuento utilizado por cliente.
- **`compras_total`**: Suma total de las ventas por cliente.
- **`compras_media`**: Promedio de las ventas por cliente.
- **`beneficio_total`**: Beneficio total generado por cliente.
- **`costo_envio_medio`**: Promedio del costo de env√≠o por cliente.

#### **Resultados de Clustering:**
- **K-Means**:
  - Dividi√≥ a los clientes en dos clusters (531 y 264 clientes).
- **Ward (Distancia Euclidiana)**:
  - Mejor√≥ la separaci√≥n con dos clusters (278 y 517 clientes), diferenciando claramente a los clientes con altos valores de ventas y en el resto de columnas, solo a excepci√≥n del descuento_medio.

---

### **Modelos de Regresi√≥n**
Los modelos se entrenaron separadamente para cada cluster generado.

#### **Primer Modelo:**
- **Cluster 0**:
  - Con una √∫nica variable num√©rica, se observ√≥ **underfitting**. El modelo con mejor desempe√±o fue Gradient Boosting.
- **Cluster 1**:
  - Persisti√≥ el underfitting, pero el Random Forest ofreci√≥ mejores m√©tricas.

#### **Segundo Modelo:**
- Se a√±adieron dos columnas demogr√°ficas (`Region` y `Country`) para mejorar las predicciones.
- Los resultados fueron mixtos:
  - **Cluster 0**: El underfitting persisti√≥, aunque con mejoras moderadas.
  - **Cluster 1**: Hubo un leve aumento en la precisi√≥n de las m√©tricas.

#### **Tercer Modelo:**
- Se mantuvieron las columnas demogr√°ficas y se eliminaron *outliers* en `Sales` y `Shipping Cost`.
- **Resultados**:
  - **Cluster 0**:
    - M√©tricas **R¬≤ > 0.8** tanto en entrenamiento como en prueba, sin se√±ales de overfitting ni underfitting.
  - **Cluster 1**:
    - Aunque las m√©tricas no fueron tan buenas como en el Cluster 0, las diferencias entre entrenamiento y prueba fueron aceptables.

---

## üìä Resultados y Conclusiones

- El m√©todo de Ward mostr√≥ ser m√°s efectivo para identificar patrones de clientes.
- La eliminaci√≥n de *outliers* , as√≠ como la inclusi√≥n de otra variable num√©rica como Quantity, mejor√≥ notablemente las m√©tricas de los modelos.
- **Cluster 0**:
  - Present√≥ un comportamiento consistente y m√©tricas superiores a **R¬≤ = 0.8**.
- **Cluster 1**:
  - Aunque las m√©tricas fueron menos precisas, las diferencias entre entrenamiento y prueba se mantuvieron en niveles razonables.

---

## üîÑ Recomendaciones 

1. Agregar el costo unitario de los art√≠culos al an√°lisis para mejorar la segmentaci√≥n.
2. Considerar trabajar con las facturas como conjuntos, en lugar de desglosarlas completamente por art√≠culos.
3. Revisar y depurar los identificadores de clientes y art√≠culos, ya que se encontraron inconsistencias como clientes con m√∫ltiples IDs.
4. Tener cuidado con la base de datos y la claridad de la informaci√≥n que se maneja, ya que se presentan casos donde un mismo cliente aparece con m√∫ltiples pa√≠ses, regiones y mercados desde los cuales compra. Esto puede sugerir la necesidad de verificar si son personas distintas registradas bajo el mismo ID.

## Pr√≥ximos pasos:

1. Manejar m√°s a fondo los outliers, tanto univariados como multivariados. 
2. Probar el ingreso de otra variable nu√©rcia como Discount, que uilic√© como categ√≥rica.
3. Probar un orden distinto de preprocesamiento.
---

## ‚úíÔ∏è Autor
- **Nelson Carvajal** - [@ngcarvajall](https://github.com/ngcarvajall)
