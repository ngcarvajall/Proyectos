![Oficina](imagen.webp)
# ğŸ“Š PredicciÃ³n de RotaciÃ³n de Empleados: Modelos de Machine Learning

## ğŸ“– DescripciÃ³n

Este proyecto aborda un problema crucial para los departamentos de Recursos Humanos: predecir quÃ© empleados tienen mayor probabilidad de dejar la empresa en el prÃ³ximo aÃ±o. A partir de datos histÃ³ricos, hemos desarrollado y evaluado modelos de Machine Learning para identificar patrones y tendencias en la rotaciÃ³n laboral.

---

## ğŸ—‚ï¸ Estructura del Proyecto

### **DistribuciÃ³n de Carpetas**
```
â”œâ”€â”€ Datos/                # Datos originales y transformados
â”‚   â”œâ”€â”€ Datos_Mod1/       # Datos del Modelo 1
â”‚   â”œâ”€â”€ Datos_Mod2/       # Datos del Modelo 2
â”‚   â”œâ”€â”€ Datos_Mod3/       # Datos del Modelo 3
â”œâ”€â”€ Modelos/              # Archivos de modelos entrenados y Notebooks de cada modelo
â”‚   â”œâ”€â”€ Modelo 1/
â”‚   â”‚   â”œâ”€â”€ 1_EDA.ipynb              # ExploraciÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ 2_Estandarizar.ipynb     # Escalado y estandarizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ 3_Encoding.ipynb         # CodificaciÃ³n de variables
â”‚   â”‚   â”œâ”€â”€ 4_MÃ©tricas.ipynb         # EvaluaciÃ³n del modelo
â”‚   â”œâ”€â”€ Modelo 2/
â”‚   â”‚   â”œâ”€â”€ 1_EDA.ipynb              # ExploraciÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ 2_OUTLIERS.ipynb         # Tratamiento de outliers
â”‚   â”‚   â”œâ”€â”€ 3_Estandarizar.ipynb     # Escalado y estandarizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ 4_MÃ©tricas.ipynb         # EvaluaciÃ³n del modelo
â”‚   â”‚   â”œâ”€â”€ 5_MÃ©tricas_Dif.ipynb     # Comparativa de mÃ©tricas usando distintos hiperparÃ¡metros
â”‚   â”œâ”€â”€ Modelo 3/
â”‚   â”‚   â”œâ”€â”€ 1_EDA.ipynb              # ExploraciÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ 2_OUTLIERS.ipynb         # Tratamiento de outliers
â”‚   â”‚   â”œâ”€â”€ 3_Estandarizar.ipynb     # Escalado y estandarizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ 4_MÃ©tricas.ipynb         # EvaluaciÃ³n del modelo
â”‚   â”‚   â”œâ”€â”€ 5_MÃ©tricas_copy.ipynb    # Comparativa de mÃ©tricas
â”‚   â”‚   â”œâ”€â”€ API.ipynb                # ImplementaciÃ³n de la API de predicciÃ³n
â”‚   â”‚   â”œâ”€â”€ main.py                  # Script principal para la API
â”‚   â”‚   â”œâ”€â”€ Streamlit.py             # Interfaz con Streamlit (en prueba)
â”œâ”€â”€ src/                  # Scripts de procesamiento y modelado
â”œâ”€â”€ README1.md             # DescripciÃ³n del proyecto
```

---

## ğŸ› ï¸ InstalaciÃ³n y Requisitos

Este proyecto utiliza Python 3.8 y las siguientes bibliotecas:

- [pandas](https://pandas.pydata.org/)
- [numpy](https://numpy.org/)
- [scikit-learn](https://scikit-learn.org/stable/)
- [imbalanced-learn](https://imbalanced-learn.org/stable/)
- [matplotlib](https://matplotlib.org/)
- [seaborn](https://seaborn.pydata.org/)
- [xgboost](https://xgboost.readthedocs.io/)
- [streamlit](https://streamlit.io/)

### InstalaciÃ³n:
1. Clona este repositorio:
   ```bash
   git clone <URL DEL REPOSITORIO>
   ```
2. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ“Š Resultados y Conclusiones

Para todos mis modelos utilicÃ© la misma secuencia de pasos de preprocesamiento:
   - **1** Tratamiento de Outliers
   - **2** EstandarizaciÃ³n de variables numÃ©ricas
   - **3** Encoding de variables categÃ³ricas

### Modelo 1:
- **Duplicados:** Se descubriÃ³ una gran cantidad de duplicados al eliminar la columna `EmployeeID`, lo que afecta la calidad del modelo.
- **Nulos:** Las variables categÃ³ricas fueron completadas con "Desconocido" y las numÃ©ricas mediante `IterativeImputer`.
- **Balanceo:** Este modelo no tiene balanceo, por lo que la variable respuesta "Attrition" estÃ¡ desbalanceada.
- **ConclusiÃ³n:** Las mÃ©tricas del modelo, especialmente usando XGBoost, son altas, pero reflejan un sobreajuste debido a los duplicados. Este modelo predictivo obtuvo mÃ©tricas de evaluaciÃ³n bastante buenas, algunas cercanas a 1 (lo Ã³ptimo). Sin embargo, identificamos que mÃ¡s del 60% de los datos del conjunto son duplicados. Esto significa que muchos de los datos del conjunto de prueba ya han sido vistos durante el entrenamiento, lo que provoca que las predicciones sean perfectas en esos casos. Como resultado, las mÃ©tricas obtenidas no reflejan la verdadera capacidad del modelo para generalizar a datos nuevos y pueden estar sobreestimadas debido a esta redundancia en los datos.

### Modelo 2:
- **ReducciÃ³n de datos:** Sin duplicados, solo queda el 40% de los datos originales.
- **Outliers:** Se eliminaron los outliers (multivariados al 100% usando el LOF) basados en vecinos 15, 25, y 35.
- **Balanceo:** Este modelo tampoco tiene balanceo, lo que afecta las mÃ©tricas.
- **ConclusiÃ³n:** Decision Tree tuvo el mejor desempeÃ±o, pero las mÃ©tricas fueron mÃ¡s realistas pero significativamente peores debido al desbalanceo con respecto al Modelo 1, ya que aunque trabajo con los datos correctos aÃºn no he balanceado.

### Modelo 3:
- **Balanceo:** Se usaron tÃ©cnicas de balanceo como Tomek y SMOTENC para equilibrar la variable respuesta en un 55-45.
- **Resultados:** Este modelo es el mÃ¡s robusto, con mÃ©tricas mÃ¡s realistas y generalizaciÃ³n adecuada.
- **ConclusiÃ³n:** Las mejores mÃ©tricas se obtuvieron con XGBoost y Gradient Boosting, sin embargo las mÃ©tricas mÃ¡s realistas, generalistas y confiables eran dadas por la regresiÃ³n logÃ­stica. Por ende me he quedado con este modelo. Debajo dejo un breve resumen de cÃ³mo fueron los resultados.

### Comparativa Final:
| **Modelo**          | **GeneralizaciÃ³n** | **Sobreajuste** | **MÃ©tricas en test** | **Velocidad** | **Comentario**                      |
|----------------------|--------------------|-----------------|----------------------|---------------|--------------------------------------|
| **RegresiÃ³n logÃ­stica** | Alta               | Bajo            | Buenas (0.87-0.88)  | Muy alta      | Consistente, eficiente, confiable.  |
| **XGBoost**          | Media              | Alto            | Muy buenas (0.91)   | Moderada      | Alto rendimiento pero sobreajusta.  |
| **Random Forest**    | Media              | Alto            | Muy buenas (0.91)   | Baja          | Costoso y sobreajustado.            |
| **Gradient Boosting**| Moderada           | Moderado        | Buenas (0.88-0.90)  | Moderada      | Competitivo, buen equilibrio.       |
| **Decision Tree**    | Baja               | Bajo            | DÃ©biles (0.79)      | Moderada      | Modelo menos competitivo.           |


# ğŸ“Š PredicciÃ³n de RotaciÃ³n de Empleados: Conclusiones

Este proyecto aborda un problema crucial para los departamentos de Recursos Humanos: predecir quÃ© empleados tienen mayor probabilidad de dejar la empresa en el prÃ³ximo aÃ±o. A partir de datos histÃ³ricos, hemos desarrollado y evaluado modelos de Machine Learning para identificar patrones y tendencias en la rotaciÃ³n laboral. 

El enfoque no solo es tÃ©cnico, sino tambiÃ©n analÃ­tico, destacando los siguientes hallazgos clave:

## ğŸ“Œ Principales Descubrimientos

- **Edad**: 
  - El punto mÃ¡s alto de rotaciÃ³n se encuentra en empleados menores de 30 aÃ±os. A partir de esa edad, las salidas disminuyen progresivamente.

- **Distancia al trabajo**:
  - Los empleados que viven a menor distancia del lugar de trabajo tienen mayor probabilidad de abandonar la empresa.

- **Salario**:
  - Aquellos con ingresos por debajo de la media son mÃ¡s propensos a salir. Esto se relaciona con la mediana salarial, que se encuentra dentro de este grupo de salidas.

- **Incrementos salariales**:
  - Aunque no se identificaron patrones muy marcados, los empleados con porcentajes de aumento salarial menores son mÃ¡s propensos a abandonar la empresa.

- **AÃ±os trabajados**:
  - El primer aÃ±o es crÃ­tico en la rotaciÃ³n laboral. La mayor parte de las salidas ocurre durante el primer aÃ±o en la empresa, bajo un nuevo manager o tras recibir un ascenso.

- **Frecuencia de viajes**:
  - Los empleados que viajan con poca frecuencia son mÃ¡s propensos a irse.

- **Departamentos**:
  - El departamento de investigaciÃ³n y desarrollo concentra la mayor fuga de empleados.

- **Nivel educativo**:
  - Los empleados con un nivel educativo intermedio (tipo 3) tienen mayor probabilidad de salir. A partir de este nivel, las salidas disminuyen, sugiriendo que empleados con mayor formaciÃ³n prefieren quedarse.

- **Campo de educaciÃ³n**:
  - Los empleados con formaciÃ³n en ciencias de la vida (Life Sciences) y medicina (Medical) presentan mayores Ã­ndices de rotaciÃ³n. Esto podrÃ­a estar relacionado con la especializaciÃ³n de la empresa y las proyecciones personales de los empleados.

- **GÃ©nero**:
  - Los hombres son el grupo con mayor probabilidad de rotaciÃ³n.

- **Nivel de puesto (JobLevel)**:
  - Los empleados en los niveles mÃ¡s bajos tienen mayores Ã­ndices de rotaciÃ³n, posiblemente asociados con salidas prematuras.

- **Tipo de rol**:
  - Tres roles destacan por su alta rotaciÃ³n: Research Scientist, Sales Executive y Laboratory Technician. Esto refleja tendencias en sectores como ciencias (ya observadas en la categorÃ­a de EducaciÃ³n) y ventas, que suelen ser Ã¡reas con alta rotaciÃ³n debido a sus exigencias.

- **Estado civil**:
  - Los empleados solteros son el grupo con mayor rotaciÃ³n, probablemente debido a una mayor flexibilidad y menos compromisos personales.

- **Entrenamientos**:
  - Los empleados que recibieron entre 2 y 3 entrenamientos en el Ãºltimo aÃ±o presentan mayores tasas de salida.

- **SatisfacciÃ³n del empleado**:
  - No se observaron diferencias significativas entre los niveles de satisfacciÃ³n.

- **Balance vida-trabajo y desempeÃ±o**:
  - Los empleados en el grupo 3 de Balance Vida-Trabajo, Job Involvement y Performance Rating tienen mayor presencia en los casos de rotaciÃ³n.

## ğŸ“ˆ Conclusiones Finales

Estos hallazgos ofrecen una visiÃ³n integral de los factores mÃ¡s relevantes que influyen en la rotaciÃ³n de empleados. La identificaciÃ³n de estos patrones no solo permite construir modelos predictivos mÃ¡s precisos, sino que tambiÃ©n facilita la implementaciÃ³n de estrategias especÃ­ficas para reducir la rotaciÃ³n laboral y mejorar la retenciÃ³n del talento.

---

## ğŸ”„ PrÃ³ximos Pasos

- Implementar tÃ©cnicas adicionales de feature engineering para mejorar la precisiÃ³n.

---

## âœ’ï¸ Autor

- **Nelson Carvajal** - [GitHub](https://github.com/ngcarvajall)
